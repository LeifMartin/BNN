{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8ca520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs are used!\n",
      "FVMF RELOADED\n",
      "GPUs are used!\n",
      "FVMF RELOADED\n",
      "GPUs are used!\n",
      "0\n",
      "Random Init Utilized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/uio/modules/rhel8/easybuild/software/Miniconda3/lmsunde/envs/BNN2/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "loss: tensor(350.0442, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(49.1581, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "2\n",
      "loss: tensor(297.2805, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(16.6147, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "3\n",
      "loss: tensor(276.6905, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(13.7142, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "4\n",
      "loss: tensor(256.4194, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(12.5797, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "5\n",
      "loss: tensor(239.7066, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(13.1582, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "6\n",
      "loss: tensor(219.7606, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(12.9421, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "7\n",
      "loss: tensor(201.7312, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(14.5659, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "8\n",
      "loss: tensor(185.6647, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(13.3476, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "9\n",
      "loss: tensor(173.3830, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(18.6385, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "10\n",
      "loss: tensor(151.2297, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(13.0648, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "Component 0 Accuracy: 901.0/1000\n",
      "Component 1 Accuracy: 907.0/1000\n",
      "Component 2 Accuracy: 895.0/1000\n",
      "Component 3 Accuracy: 893.0/1000\n",
      "Component 4 Accuracy: 897.0/1000\n",
      "Component 5 Accuracy: 895.0/1000\n",
      "Component 6 Accuracy: 888.0/1000\n",
      "Component 7 Accuracy: 906.0/1000\n",
      "Component 8 Accuracy: 900.0/1000\n",
      "Component 9 Accuracy: 895.0/1000\n",
      "Posterior Mean Accuracy: 912.0/1000\n",
      "Ensemble Accuracy: 906/1000\n"
     ]
    }
   ],
   "source": [
    "#matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import time\n",
    "import mpmath\n",
    "import os\n",
    "\n",
    "import importlib\n",
    "import FVMF\n",
    "importlib.reload(FVMF)\n",
    "import test_ensemble\n",
    "importlib.reload(test_ensemble)\n",
    "\n",
    "prefix = \"_phoneme_bg_\"\n",
    "# define the summary writer\n",
    "writer = SummaryWriter()\n",
    "sns.set()\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_palette(\"muted\")\n",
    "sns.set_color_codes(\"muted\")\n",
    "\n",
    "\n",
    "# select the device\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "cuda = torch.cuda.set_device(1)\n",
    "\n",
    "if (torch.cuda.is_available()):\n",
    "    print(\"GPUs are used!\")\n",
    "else:\n",
    "    print(\"CPUs are used!\")\n",
    "\n",
    "# define the parameters\n",
    "BATCH_SIZE = 100\n",
    "TEST_BATCH_SIZE = 100\n",
    "COND_OPT = False\n",
    "CLASSES = 5\n",
    "# TRAIN_EPOCHS = 250\n",
    "SAMPLES = 1\n",
    "TEST_SAMPLES = 10\n",
    "TEMPER = 0.001\n",
    "TEMPER_PRIOR = 0.001\n",
    "pepochs = 50\n",
    "\n",
    "#prepare the data\n",
    "data = pd.read_csv('http://www.uio.no/studier/emner/matnat/math/STK2100/data/phoneme.data')\n",
    "data = data.drop(columns=[\"row.names\"])\n",
    "data = pd.concat([data,data.g.astype(\"category\").cat.codes.astype(int)],sort=False, axis=1) #get_dummies(data['g'], prefix='phoneme')],sort=False, axis=1)\n",
    "data = data.drop(columns=[\"g\",\"speaker\"])\n",
    "data = data.values\n",
    "\n",
    "np.random.seed(40590)\n",
    "\n",
    "tr_ids = np.random.choice(4509, 3500, replace = False)\n",
    "te_ids = np.setdiff1d(np.arange(4509),tr_ids)[0:1000]\n",
    "\n",
    "dtrain = data[tr_ids,:]\n",
    "\n",
    "data_mean = dtrain.mean(axis=0)[0:256]\n",
    "data_std = dtrain.std(axis=0)[0:256]\n",
    "\n",
    "data[:,0:256] = (data[:,0:256]  - data_mean)/data_std\n",
    "\n",
    "dtrain = data[tr_ids,:]\n",
    "dtest = data[te_ids,:]\n",
    "\n",
    "\n",
    "# set prior parameters\n",
    "PI = 1\n",
    "SIGMA_1 = torch.cuda.FloatTensor([math.exp(-0)])\n",
    "SIGMA_2 = torch.cuda.FloatTensor([math.exp(-6)])\n",
    "\n",
    "\n",
    "#The net does not like to get larger at a given layer??\n",
    "l1shape=(256, 10)\n",
    "l2shape=(10, 10)\n",
    "l3shape=(10, 10)\n",
    "l4shape=(10, 5)\n",
    "layershapes = [l1shape, l2shape, l3shape, l4shape]\n",
    "\n",
    "epochs = 10\n",
    "trtimes  = []\n",
    "# make inference on 10 networks\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net = FVMF.BayesianNetwork(layershapes=layershapes,BN='notbatchnorm',VD='Gaussian',\n",
    "                               dtrain=dtrain,dtest=dtest,BATCH_SIZE = 100,classification = 'classification').to(DEVICE)\n",
    "    #net = VMF.BayesianNetwork(l1=l1shape, l2=l2shape, l3=l3shape,l4=l4shape,BN='notbatchnorm').to(DEVICE)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.007)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train = FVMF.train(net, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100,shape = (0,256,256,257))\n",
    "        trtimes.append(train[1].detach().cpu().numpy())\n",
    "        #print(net.l1.weight_mu.mean())\n",
    "\n",
    "    res = test_ensemble.test_ensemble(net,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = (0,256,256,257))\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f26701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = []\n",
    "for i in range(epochs):\n",
    "    x.append(i+1)\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Gaussian loss, 10 epoch phoneme classification')\n",
    "plt.plot(x,trtimes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0470924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs are used!\n",
      "FVMF RELOADED\n",
      "0\n",
      "Random Init Utilized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/uio/modules/rhel8/easybuild/software/Miniconda3/lmsunde/envs/BNN2/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "loss: tensor(208.9301, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(53.8483, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(4.3046, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(15.0372, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "2\n",
      "loss: tensor(198.2865, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(17.0525, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(4.9646, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(17.5934, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "3\n",
      "loss: tensor(169.0435, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(19.6990, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(5.8137, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(18.7951, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "4\n",
      "loss: tensor(159.2988, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.4887, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(6.0600, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(19.6949, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "5\n",
      "loss: tensor(151.0041, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(14.3832, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(5.7620, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(20.1119, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "6\n",
      "loss: tensor(151.0792, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.2204, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(5.8024, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(20.8421, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "7\n",
      "loss: tensor(155.1925, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(14.7052, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(5.8406, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(21.4846, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "8\n",
      "loss: tensor(137.3520, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.1184, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(5.6750, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(22.5660, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "9\n",
      "loss: tensor(149.0735, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.7006, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(5.7705, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(23.2992, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "10\n",
      "loss: tensor(168.7990, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(19.3322, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(6.0163, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(24.8719, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "Component 0 Accuracy: 926.0/1000\n",
      "Component 1 Accuracy: 917.0/1000\n",
      "Component 2 Accuracy: 915.0/1000\n",
      "Component 3 Accuracy: 920.0/1000\n",
      "Component 4 Accuracy: 918.0/1000\n",
      "Component 5 Accuracy: 929.0/1000\n",
      "Component 6 Accuracy: 922.0/1000\n",
      "Component 7 Accuracy: 931.0/1000\n",
      "Component 8 Accuracy: 909.0/1000\n",
      "Component 9 Accuracy: 918.0/1000\n",
      "Posterior Mean Accuracy: 927.0/1000\n",
      "Ensemble Accuracy: 928/1000\n"
     ]
    }
   ],
   "source": [
    "#import importlib\n",
    "#import os\n",
    "import FVMF\n",
    "importlib.reload(FVMF)\n",
    "\n",
    "#import VMF\n",
    "\n",
    "#import importlib\n",
    "#importlib.reload(VMF)\n",
    "\n",
    "prefix = \"_phoneme_bg_\"\n",
    "# define the summary writer\n",
    "writer = SummaryWriter()\n",
    "sns.set()\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_palette(\"muted\")\n",
    "sns.set_color_codes(\"muted\")\n",
    "\n",
    "\n",
    "# select the device\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "cuda = torch.cuda.set_device(1)\n",
    "\n",
    "# define the parameters\n",
    "BATCH_SIZE = 100\n",
    "TEST_BATCH_SIZE = 100\n",
    "batch_size = 100\n",
    "COND_OPT = False\n",
    "CLASSES = 5\n",
    "# TRAIN_EPOCHS = 250\n",
    "SAMPLES = 1\n",
    "TEST_SAMPLES = 10\n",
    "TEMPER = 0.001\n",
    "TEMPER_PRIOR = 0.001\n",
    "pepochs = 50\n",
    "\n",
    "#prepare the data\n",
    "data = pd.read_csv('http://www.uio.no/studier/emner/matnat/math/STK2100/data/phoneme.data')\n",
    "data = data.drop(columns=[\"row.names\"])\n",
    "data = pd.concat([data,data.g.astype(\"category\").cat.codes.astype(int)],sort=False, axis=1) #get_dummies(data['g'], prefix='phoneme')],sort=False, axis=1)\n",
    "data = data.drop(columns=[\"g\",\"speaker\"])\n",
    "data = data.values\n",
    "\n",
    "np.random.seed(40590)\n",
    "\n",
    "tr_ids = np.random.choice(4509, 3500, replace = False)\n",
    "te_ids = np.setdiff1d(np.arange(4509),tr_ids)[0:1000]\n",
    "\n",
    "dtrain = data[tr_ids,:]\n",
    "\n",
    "data_mean = dtrain.mean(axis=0)[0:256]\n",
    "data_std = dtrain.std(axis=0)[0:256]\n",
    "\n",
    "data[:,0:256] = (data[:,0:256]  - data_mean)/data_std\n",
    "\n",
    "dtrain = data[tr_ids,:]\n",
    "dtest = data[te_ids,:]\n",
    "\n",
    "# set prior parameters\n",
    "PI = 1\n",
    "SIGMA_1 = torch.cuda.FloatTensor([math.exp(-0)])\n",
    "SIGMA_2 = torch.cuda.FloatTensor([math.exp(-6)])\n",
    "\n",
    "epochs = 10\n",
    "trtimes  = []\n",
    "#w_mu = [w_mu1, w_mu2, w_mu3, w_mu4]\n",
    "#b_mu = [b_mu1, b_mu2, b_mu3, b_mu4]\n",
    "\n",
    "#w_mu_nodewise = [w_mu1_nodewise,w_mu2_nodewise,w_mu3_nodewise,w_mu4_nodewise]\n",
    "#b_mu_nodewise = [b_mu1_nodewise,b_mu2_nodewise,b_mu3_nodewise,b_mu4_nodewise]\n",
    "# make inference on 10 networks\n",
    "\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net2 = FVMF.BayesianNetwork(#w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa=torch.Tensor(1).uniform_(4,4.1),\n",
    "                                w_kappa=torch.Tensor(1).uniform_(6.5,6.6),\n",
    "                                Temper = 1, normalize = 'No',classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #p.requires_grad_(False)\n",
    "    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net2.parameters(), lr=0.14)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train = FVMF.train(net2, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100,shape = (0,256,256,257))\n",
    "        trtimes.append(train[1].detach().cpu().numpy())\n",
    "        \n",
    "        print('max:',net2.weight_mu[1].max())\n",
    "        print('norm:',torch.norm(net2.weight_mu[1]))\n",
    "\n",
    "    res = test_ensemble.test_ensemble(net2,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = (0,256,256,257))\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb045e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('vMF loss curve, 10 epoch phoneme classification')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(x,trtimes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43089ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Random Init Utilized\n",
      "1\n",
      "loss: tensor(412.0250, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(100.9529, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "2\n",
      "loss: tensor(338.8826, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(37.1010, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "3\n",
      "loss: tensor(317.0960, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(22.0465, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "4\n",
      "loss: tensor(303.8429, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(17.2404, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "5\n",
      "loss: tensor(295.4734, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.6428, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "6\n",
      "loss: tensor(285.1866, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(14.7633, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "7\n",
      "loss: tensor(275.3525, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(14.6446, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "8\n",
      "loss: tensor(268.0175, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(12.7891, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "9\n",
      "loss: tensor(261.3266, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.3482, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "10\n",
      "loss: tensor(249.2289, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(12.3045, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "11\n",
      "loss: tensor(245.0613, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.0957, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "12\n",
      "loss: tensor(234.5600, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(11.8954, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "13\n",
      "loss: tensor(227.4901, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(12.8290, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "14\n",
      "loss: tensor(216.2930, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(12.3220, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "15\n",
      "loss: tensor(207.3024, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(11.2361, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "16\n",
      "loss: tensor(203.1301, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(12.1892, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "17\n",
      "loss: tensor(192.1960, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(10.4158, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "18\n",
      "loss: tensor(187.3672, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(10.1712, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "19\n",
      "loss: tensor(178.4584, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(10.4106, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "20\n",
      "loss: tensor(174.6434, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(11.2875, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "21\n",
      "loss: tensor(165.7438, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(9.9802, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "22\n",
      "loss: tensor(162.1314, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(13.4813, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "23\n",
      "loss: tensor(156.3064, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(13.5954, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "24\n",
      "loss: tensor(148.1391, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(11.7649, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "25\n",
      "loss: tensor(145.0571, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(13.3481, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "26\n",
      "loss: tensor(141.4604, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.3187, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "27\n",
      "loss: tensor(135.8599, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.3963, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "28\n",
      "loss: tensor(132.0691, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.7413, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "29\n",
      "loss: tensor(123.0882, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(11.5974, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "30\n",
      "loss: tensor(122.8189, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(12.9193, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "Component 0 Accuracy: 911.0/1000\n",
      "Component 1 Accuracy: 929.0/1000\n",
      "Component 2 Accuracy: 915.0/1000\n",
      "Component 3 Accuracy: 915.0/1000\n",
      "Component 4 Accuracy: 916.0/1000\n",
      "Component 5 Accuracy: 920.0/1000\n",
      "Component 6 Accuracy: 920.0/1000\n",
      "Component 7 Accuracy: 913.0/1000\n",
      "Component 8 Accuracy: 926.0/1000\n",
      "Component 9 Accuracy: 918.0/1000\n",
      "Posterior Mean Accuracy: 924.0/1000\n",
      "Ensemble Accuracy: 924/1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 30\n",
    "trtimes  = []\n",
    "# make inference on 10 networks\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net = FVMF.BayesianNetwork(layershapes=layershapes,BN='notbatchnorm',VD='Gaussian',\n",
    "                               dtrain=dtrain,dtest=dtest,BATCH_SIZE = 100,classification = 'classification').to(DEVICE)\n",
    "    #net = VMF.BayesianNetwork(l1=l1shape, l2=l2shape, l3=l3shape,l4=l4shape,BN='notbatchnorm').to(DEVICE)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.003)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train = FVMF.train(net, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100,shape = (0,256,256,257))\n",
    "        trtimes.append(train[1].detach().cpu().numpy())\n",
    "        #print(net.l1.weight_mu.mean())\n",
    "\n",
    "    res = test_ensemble.test_ensemble(net,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = (0,256,256,257))\n",
    "x = []\n",
    "for i in range(epochs):\n",
    "    x.append(i+1)\n",
    "plt.title('Gaussian loss curve, 30 epoch phoneme classification')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(x,trtimes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b5f684c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Random Init Utilized\n",
      "1\n",
      "loss: tensor(208.9301, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(53.8483, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(4.3046, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(15.0372, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "2\n",
      "loss: tensor(198.2865, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(17.0525, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(4.9646, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(17.5934, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "3\n",
      "loss: tensor(169.0435, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(19.6990, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(5.8137, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(18.7951, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "4\n",
      "loss: tensor(159.2988, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.4887, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(6.0600, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(19.6949, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "5\n",
      "loss: tensor(151.0041, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(14.3832, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(5.7620, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(20.1119, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "6\n",
      "loss: tensor(151.0792, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.2204, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(5.8024, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(20.8421, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "7\n",
      "loss: tensor(155.1925, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(14.7052, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(5.8406, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(21.4846, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "8\n",
      "loss: tensor(137.3520, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.1184, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(5.6750, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(22.5660, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "9\n",
      "loss: tensor(149.0735, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.7006, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(5.7705, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(23.2992, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "10\n",
      "loss: tensor(168.7990, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(19.3322, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(6.0163, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(24.8719, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "0\n",
      "1\n",
      "loss: tensor(175.9626, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(24.6839, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(6.7930, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(25.4142, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "2\n",
      "loss: tensor(169.5107, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(23.1208, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(6.5530, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(25.6366, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "3\n",
      "loss: tensor(175.0326, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(30.2239, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(6.7496, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(25.8377, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "4\n",
      "loss: tensor(153.9016, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(14.9802, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(6.8890, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(26.0295, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "5\n",
      "loss: tensor(146.4464, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(20.0211, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.1052, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(26.1343, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "6\n",
      "loss: tensor(143.8071, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(22.7741, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.3318, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(26.3909, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "7\n",
      "loss: tensor(148.4807, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(23.9754, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.3959, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(26.7495, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "8\n",
      "loss: tensor(137.8083, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(12.8863, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.3375, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(26.8614, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "9\n",
      "loss: tensor(142.0676, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(14.0049, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.3341, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(27.2422, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "10\n",
      "loss: tensor(144.4185, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(17.8519, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.6089, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(27.4860, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "0\n",
      "1\n",
      "loss: tensor(150.7797, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(21.2509, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.6059, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(27.4984, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "2\n",
      "loss: tensor(152.7066, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(27.7154, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.8112, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(27.6162, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "3\n",
      "loss: tensor(158.5523, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(35.5135, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.7768, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(27.6123, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "4\n",
      "loss: tensor(138.2453, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(17.7816, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.9629, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(27.5319, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "5\n",
      "loss: tensor(133.5146, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(15.3635, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(8.0219, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(27.6784, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "6\n",
      "loss: tensor(141.4330, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(20.1807, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.8702, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(27.7687, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "7\n",
      "loss: tensor(134.9374, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(16.3291, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.7549, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(27.8082, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "8\n",
      "loss: tensor(136.1303, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(17.9573, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.7529, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(27.8599, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "9\n",
      "loss: tensor(136.1947, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(17.0917, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(7.8764, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(27.9733, device='cuda:1', grad_fn=<NormBackward1>)\n",
      "10\n",
      "loss: tensor(135.6604, device='cuda:1', grad_fn=<AddBackward0>)\n",
      "negative_log_likelihood: tensor(18.6703, device='cuda:1', grad_fn=<NllLossBackward0>)\n",
      "max: tensor(8.0526, device='cuda:1', grad_fn=<MaxBackward1>)\n",
      "norm: tensor(28.0000, device='cuda:1', grad_fn=<NormBackward1>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trtimes = []\n",
    "epochs = 10\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net2 = FVMF.BayesianNetwork(#w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa=torch.Tensor(1).uniform_(4,4.1),\n",
    "                                w_kappa=torch.Tensor(1).uniform_(6.5,6.6),\n",
    "                                Temper = 1, normalize = 'No',classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #p.requires_grad_(False)\n",
    "    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net2.parameters(), lr=0.14)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train = FVMF.train(net2, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100,shape = (0,256,256,257))\n",
    "        trtimes.append(train[1].detach().cpu().numpy())\n",
    "        \n",
    "        print('max:',net2.weight_mu[1].max())\n",
    "        print('norm:',torch.norm(net2.weight_mu[1]))\n",
    "\n",
    "    #res = test_ensemble.test_ensemble(net2,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = (0,256,256,257))\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")\n",
    "    \n",
    "w_mu = []\n",
    "for i in range(len(net2.weight_mu)):\n",
    "    #print('\\n','torch.norm(net4.weight_mu[i]):',torch.norm(net4.weight_mu[i]))\n",
    "    w_mu.append(net2.weight_mu[i]/torch.norm(net2.weight_mu[i]))\n",
    "    #print('\\n','norm w_mu[i]',torch.norm(w_mu[i]))\n",
    "    \n",
    "b_mu = []\n",
    "for i in range(len(net2.bias_mu)):\n",
    "    #print('\\n','torch.norm(net4.bais_mu[i]):',torch.norm(net4.bias_mu[i]))\n",
    "    b_mu.append(net2.bias_mu[i]/torch.norm(net2.bias_mu[i]))\n",
    "    #print('\\n','norm b_mu[i]',torch.norm(b_mu[i]))\n",
    "    \n",
    "b_rho= []\n",
    "for i in range(len(net2.bias_rho)):\n",
    "    b_rho.append(net2.bias_rho[i])\n",
    "\n",
    "w_rho= []\n",
    "for i in range(len(net2.weight_rho)):\n",
    "    w_rho.append(net2.weight_rho[i])\n",
    "\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net2_2 = FVMF.BayesianNetwork(w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa= b_rho, #torch.Tensor(1).uniform_(1.0,3.1), \n",
    "                                w_kappa= w_rho,\n",
    "                                Temper = 1, normalize = 'No',classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #p.requires_grad_(False)\n",
    "    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net2_2.parameters(), lr=0.07)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train = FVMF.train(net2_2, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100,shape = (0,256,256,257))\n",
    "        trtimes.append(train[1].detach().cpu().numpy())\n",
    "        \n",
    "        print('max:',net2_2.weight_mu[1].max())\n",
    "        print('norm:',torch.norm(net2_2.weight_mu[1]))\n",
    "\n",
    "    #res = test_ensemble.test_ensemble(net2,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = (0,256,256,257))\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")\n",
    "\n",
    "w_mu = []\n",
    "for i in range(len(net2_2.weight_mu)):\n",
    "    #print('\\n','torch.norm(net4.weight_mu[i]):',torch.norm(net4.weight_mu[i]))\n",
    "    w_mu.append(net2_2.weight_mu[i]/torch.norm(net2_2.weight_mu[i]))\n",
    "    #print('\\n','norm w_mu[i]',torch.norm(w_mu[i]))\n",
    "    \n",
    "b_mu = []\n",
    "for i in range(len(net2_2.bias_mu)):\n",
    "    #print('\\n','torch.norm(net4.bais_mu[i]):',torch.norm(net4.bias_mu[i]))\n",
    "    b_mu.append(net2_2.bias_mu[i]/torch.norm(net2_2.bias_mu[i]))\n",
    "    #print('\\n','norm b_mu[i]',torch.norm(b_mu[i]))\n",
    "    \n",
    "b_rho= []\n",
    "for i in range(len(net2_2.bias_rho)):\n",
    "    b_rho.append(net2_2.bias_rho[i])\n",
    "\n",
    "w_rho= []\n",
    "for i in range(len(net2_2.weight_rho)):\n",
    "    w_rho.append(net2_2.weight_rho[i])\n",
    "    \n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net2_2_2 = FVMF.BayesianNetwork(w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa= b_rho, #torch.Tensor(1).uniform_(1.0,3.1), \n",
    "                                w_kappa= w_rho,\n",
    "                                Temper = 1, normalize = 'No',classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #p.requires_grad_(False)\n",
    "    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net2_2_2.parameters(), lr=0.035)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        train = FVMF.train(net2_2_2, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100,shape = (0,256,256,257))\n",
    "        trtimes.append(train[1].detach().cpu().numpy())\n",
    "        \n",
    "        print('max:',net2_2_2.weight_mu[1].max())\n",
    "        print('norm:',torch.norm(net2_2_2.weight_mu[1]))\n",
    "\n",
    "    #res = test_ensemble.test_ensemble(net2,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = (0,256,256,257))\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")\n",
    "plt.title('vMF loss, 30 epoch phoneme classification with NII')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(x,trtimes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b57c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component 0 Accuracy: 889.0/1000\n",
      "Component 1 Accuracy: 854.0/1000\n",
      "Component 2 Accuracy: 894.0/1000\n",
      "Component 3 Accuracy: 890.0/1000\n",
      "Component 4 Accuracy: 866.0/1000\n",
      "Component 5 Accuracy: 881.0/1000\n",
      "Component 6 Accuracy: 885.0/1000\n",
      "Component 7 Accuracy: 858.0/1000\n",
      "Component 8 Accuracy: 892.0/1000\n",
      "Component 9 Accuracy: 858.0/1000\n",
      "Posterior Mean Accuracy: 927.0/1000\n",
      "Ensemble Accuracy: 917/1000\n"
     ]
    }
   ],
   "source": [
    "res = test_ensemble.test_ensemble(net2_2,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = (0,256,256,257))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24216e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(42069)\n",
    "torch.manual_seed(42069)\n",
    "\n",
    "PL = [torch.Tensor([1-3, 1-3]),torch.Tensor([5-3, 1-3]),torch.Tensor([1-3, 5-3]),torch.Tensor([5-3, 5-3]),torch.Tensor([3-3, 3-3])]\n",
    "cov = torch.eye(2)\n",
    "n = 250\n",
    "\n",
    "plt.figure(figsize=(10, 10), dpi=500)\n",
    "distrib = []\n",
    "\n",
    "DF = torch.zeros((len(PL),n,1,3)) #multiple of 4\n",
    "for i, MU in enumerate(PL): #enumerate starts from and including 0.\n",
    "    distrib.append(torch.distributions.multivariate_normal.MultivariateNormal(loc=MU, covariance_matrix=cov))\n",
    "    DATA_ = distrib[i].sample((n,1))\n",
    "\n",
    "    DATA  = torch.zeros([n, 1, 3])\n",
    "    DATA[:,:,:2] = DATA_\n",
    "    DATA[:,:,2]  = i\n",
    "    DF[i,:,:,:] = DATA\n",
    "    \n",
    "    x = DATA[:,0,0]\n",
    "    y = DATA[:,0,1]\n",
    "    plt.plot(x,y,'.',markersize=1.25)\n",
    "plt.show()\n",
    "\n",
    "C = int(3*n/4)\n",
    "\n",
    "#DATA_train = torch.zeros((len(PL)*C,3))\n",
    "#DATA_test = torch.zeros((len(PL)*(n-C),3))\n",
    "\n",
    "DATA = DF.reshape(len(PL)*n,3)\n",
    "#print('DATA:',DATA,'len(DATA):',len(DATA),'mean dtrain:',DATA.mean(axis=0)[2])\n",
    "\n",
    "#data_mean = DATA.mean(axis=1)[0:2]\n",
    "#data_std = DATA.std(axis=1)[0:2]\n",
    "\n",
    "#DATA[:,0:2] = (DATA[:,0:2]  - data_mean)/data_std\n",
    "#print('DATA normalized:',DATA,'len(DATA) normalized:',len(DATA),'mean dtrain normalized:',DATA.mean(axis=0)[2])\n",
    "tr_ids = np.random.choice(n*5, n*4, replace = False)\n",
    "\n",
    "\n",
    "\n",
    "dtrain = DATA[tr_ids,:]\n",
    "dtest = DATA[-tr_ids,:]\n",
    "\n",
    "#print('\\n','dtrain:',dtrain, 'len(dtrain):',len(dtrain),'mean dtrain:',dtrain.mean(axis=0)[2])\n",
    "#print('\\n','dtest:',dtest, 'len(dtest):',len(dtest),'mean dtest:',dtest.mean(axis=0)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47628290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import time\n",
    "import mpmath\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "\n",
    "import test_ensemble\n",
    "importlib.reload(test_ensemble)\n",
    "import FVMF\n",
    "importlib.reload(FVMF)\n",
    "\n",
    "# define the summary writer\n",
    "writer = SummaryWriter()\n",
    "# select the device\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "cuda = torch.cuda.set_device(1)\n",
    "\n",
    "# define the parameters\n",
    "\n",
    "COND_OPT = False\n",
    "CLASSES = 5\n",
    "# TRAIN_EPOCHS = 250\n",
    "SAMPLES = 1\n",
    "TEST_SAMPLES = 10\n",
    "TEMPER = 0.001\n",
    "TEMPER_PRIOR = 0.001\n",
    "pepochs = 50\n",
    "TEST_BATCH_SIZE = 100\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "l1shape=(2, 5)\n",
    "l2shape=(5, 5)\n",
    "l3shape=(5, 5)\n",
    "l4shape=(5, 5)\n",
    "l5shape=(5, 5)\n",
    "l6shape=(5, 5)\n",
    "layershapes = [l1shape, l2shape, l3shape, l4shape]\n",
    "\n",
    "# set prior parameters\n",
    "PI = 1\n",
    "SIGMA_1 = torch.cuda.FloatTensor([math.exp(-0)])\n",
    "SIGMA_2 = torch.cuda.FloatTensor([math.exp(-6)])\n",
    "data_shape = (0,2,2,3)\n",
    "\n",
    "epochs = 30\n",
    "trtimes  = np.zeros(epochs)\n",
    "#w_mu = [w_mu1, w_mu2, w_mu3, w_mu4]\n",
    "#b_mu = [b_mu1, b_mu2, b_mu3, b_mu4]\n",
    "\n",
    "#w_mu_nodewise = [w_mu1_nodewise,w_mu2_nodewise,w_mu3_nodewise,w_mu4_nodewise]\n",
    "#b_mu_nodewise = [b_mu1_nodewise,b_mu2_nodewise,b_mu3_nodewise,b_mu4_nodewise]\n",
    "# make inference on 10 networks\n",
    "\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net3 = FVMF.BayesianNetwork(#w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='Gaussian',\n",
    "                                #b_kappa=torch.Tensor(1).uniform_(4,4.1),\n",
    "                                #w_kappa=torch.Tensor(1).uniform_(6,6.1),\n",
    "                                Temper = 1,classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net3.parameters(), lr=0.04)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net3, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100, shape = data_shape)\n",
    "        print('max:',net3.weight_mu[1].max())\n",
    "        print('norm:',torch.norm(net3.weight_mu[1]))\n",
    "\n",
    "    res = test_ensemble.test_ensemble(net3,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = data_shape)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3171283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_ensemble\n",
    "importlib.reload(test_ensemble)\n",
    "import FVMF\n",
    "importlib.reload(FVMF)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net4 = FVMF.BayesianNetwork(#w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa=torch.Tensor(1).uniform_(4.0,4.1),\n",
    "                                w_kappa=torch.Tensor(1).uniform_(6.0,6.1),\n",
    "                                Temper = 1,classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net4.parameters(), lr=0.14)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net4, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100, shape = data_shape)\n",
    "        #print('max:',net4.weight_mu[1].max())\n",
    "        #print('norm:',torch.norm(net4.weight_mu[1]))\n",
    "\n",
    "    #res = test_ensemble.test_ensemble(net4,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = data_shape)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_intensity = 1\n",
    "\n",
    "#Kanskje er det en god idee å også arve kappaene, men doble? Hva om vi også kjører på med litt normalizering av mu-ene her?\n",
    "#Hva med adaptiv kappa per lag? Det er jo bare en kappa per bias-lag.\n",
    "\n",
    "w_mu = []\n",
    "for i in range(len(net4.weight_mu)):\n",
    "    #print('\\n','torch.norm(net4.weight_mu[i]):',torch.norm(net4.weight_mu[i]))\n",
    "    w_mu.append(net4.weight_mu[i]/torch.norm(net4.weight_mu[i]))\n",
    "    #print('\\n','norm w_mu[i]',torch.norm(w_mu[i]))\n",
    "    \n",
    "b_mu = []\n",
    "for i in range(len(net4.bias_mu)):\n",
    "    #print('\\n','torch.norm(net4.bais_mu[i]):',torch.norm(net4.bias_mu[i]))\n",
    "    b_mu.append(net4.bias_mu[i]/torch.norm(net4.bias_mu[i]))\n",
    "    #print('\\n','norm b_mu[i]',torch.norm(b_mu[i]))\n",
    "    \n",
    "b_rho= []\n",
    "for i in range(len(net4.bias_rho)):\n",
    "    b_rho.append(net4.bias_rho[i]*GC_intensity)\n",
    "\n",
    "w_rho= []\n",
    "for i in range(len(net4.weight_rho)):\n",
    "    w_rho.append(net4.weight_rho[i]*GC_intensity)\n",
    "\n",
    "#print('b_rho:',b_rho, '\\n','w_rho:',b_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net4_GC = FVMF.BayesianNetwork(w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa= b_rho, #torch.Tensor(1).uniform_(1.0,3.1), \n",
    "                                w_kappa= w_rho, #torch.Tensor(1).uniform_(2.0,4.1), \n",
    "                                Temper = 1,classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net4_GC.parameters(), lr=0.07)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net4_GC, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100, shape = data_shape)\n",
    "        #print('max:',net4.weight_mu[1].max())\n",
    "        #print('norm:',torch.norm(net4.weight_mu[1]))\n",
    "\n",
    "    #res = test_ensemble.test_ensemble(net4_GC,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = data_shape)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")\n",
    "#print('This is the loss with the Gradient Capture method/Normalized Initialization Inheritance')\n",
    "\n",
    "#Ok, så kanskje drit i gradient-capture-method. Men! Husk hva du har vist her nå med kun normalisering av vektene, Du får trent nettet\n",
    "#Videre, og det fungerer faktisk. I tilfellet hvor du ikke gjør det ender du faktisk ikke bare opp med dårlig ytelse, men\n",
    "#hele nettet brekker!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_intensity = 1\n",
    "\n",
    "#Kanskje er det en god idee å også arve kappaene, men halvere dem? Hva om vi også kjører på med litt normalizering av mu-ene her?\n",
    "#Hva med adaptiv kappa per lag? Det er jo bare en kappa per bias-lag. GC fungerer rett og slett ikke.\n",
    "\n",
    "w_mu = []\n",
    "for i in range(len(net4_GC.weight_mu)):\n",
    "    #print('\\n','torch.norm(net4.weight_mu[i]):',torch.norm(net4.weight_mu[i]))\n",
    "    w_mu.append(net4_GC.weight_mu[i]/torch.norm(net4_GC.weight_mu[i]))\n",
    "    #print('\\n','norm w_mu[i]',torch.norm(w_mu[i]))\n",
    "    \n",
    "b_mu = []\n",
    "for i in range(len(net4_GC.bias_mu)):\n",
    "    #print('\\n','torch.norm(net4.bais_mu[i]):',torch.norm(net4.bias_mu[i]))\n",
    "    b_mu.append(net4_GC.bias_mu[i]/torch.norm(net4_GC.bias_mu[i]))\n",
    "    #print('\\n','norm b_mu[i]',torch.norm(b_mu[i]))\n",
    "    \n",
    "b_rho= []\n",
    "for i in range(len(net4_GC.bias_rho)):\n",
    "    b_rho.append(net4_GC.bias_rho[i]*GC_intensity)\n",
    "\n",
    "w_rho= []\n",
    "for i in range(len(net4_GC.weight_rho)):\n",
    "    w_rho.append(net4_GC.weight_rho[i]*GC_intensity)\n",
    "\n",
    "#print('b_rho:',b_rho, '\\n','w_rho:',b_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe30de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net4_GC2 = FVMF.BayesianNetwork(w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa= b_rho, #torch.Tensor(1).uniform_(1.0,3.1), \n",
    "                                w_kappa= w_rho, #torch.Tensor(1).uniform_(2.0,4.1), \n",
    "                                Temper = 1,classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net4_GC2.parameters(), lr=0.035)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net4_GC2, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100, shape = data_shape)\n",
    "        #print('max:',net4.weight_mu[1].max())\n",
    "        #print('norm:',torch.norm(net4.weight_mu[1]))\n",
    "\n",
    "    res = test_ensemble.test_ensemble(net4_GC2,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = data_shape)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")\n",
    "print('This is the loss with the Gradient Capture method/Normalized Initialization Inheritance, applied twice')\n",
    "\n",
    "#Ok, så kanskje drit i gradient-capture-method. Men! Husk hva du har vist her nå med kun normalisering av vektene, Du får trent nettet\n",
    "#Videre, og det fungerer faktisk. I tilfellet hvor du ikke gjør det ender du faktisk ikke bare opp med dårlig ytelse, men\n",
    "#hele nettet brekker!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84652247",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES = 1028 #Ca. Full HD resolution. If you struggle with memory adjust this parameter down. 64 for example already gives a decent view.\n",
    "enums = 10\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "Temps = torch.zeros((RES**2,3))\n",
    "i, j = 0, 0\n",
    "\n",
    "x = torch.linspace(-5,5,RES)\n",
    "\n",
    "Temps[:,:2] = torch.cartesian_prod(x, x)\n",
    "probs = torch.zeros((1,5)).to(DEVICE)\n",
    "\n",
    "for j in range(enums):\n",
    "    probs = probs + torch.exp(net4_GC2(Temps[:,0:2])) #This is done enums times, each one will be different due to stochastic.\n",
    "probs = probs/enums\n",
    "\n",
    "Temps[:,2] = -torch.sum(probs * torch.log(probs),dim = 1)\n",
    "print(torch.max(Temps[:,2]),torch.min(Temps[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7fe0b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title('vMF Uncertainty Plot 42epocsLR0.1 3*10epocs, NII in between.')\n",
    "#xy = [0,0.2,0.4,0.6,0.8,1]\n",
    "#z = xy\n",
    "plot = plt.scatter(Temps[:,0].detach().numpy(), Temps[:,1].detach().numpy(),vmin = 0, vmax = 1.4, s=221000/(RES**2), c=Temps[:,2].detach().numpy(), cmap='RdYlBu', marker='s')\n",
    "plt.gcf().set_size_inches((14, 12))\n",
    "plt.colorbar(plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca69ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RES = 1028\n",
    "enums = 10\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "Temps2 = torch.zeros((RES**2,3))\n",
    "i, j = 0, 0\n",
    "\n",
    "x = torch.linspace(-5,5,RES)\n",
    "\n",
    "Temps2[:,:2] = torch.cartesian_prod(x, x)\n",
    "probs = torch.zeros((1,5)).to(DEVICE)\n",
    "\n",
    "for j in range(enums):\n",
    "    probs = probs + torch.exp(net3(Temps2[:,0:2])) #This is done enums times, each one will be different due to stochastic.\n",
    "probs = probs/enums\n",
    "\n",
    "Temps2[:,2] = -torch.sum(probs * torch.log(probs),dim = 1)\n",
    "print(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065f450",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title('Gaussian Uncertainty Plot')\n",
    "#xy = [0,0.2,0.4,0.6,0.8,1]\n",
    "#z = xy\n",
    "plot2 = plt.scatter(Temps2[:,0].detach().numpy(), Temps2[:,1].detach().numpy(),vmin = 0, vmax = 1.4, s=221000/(RES**2), c=Temps2[:,2].detach().numpy(), cmap='RdYlBu', marker='s')\n",
    "plt.gcf().set_size_inches((14, 12))\n",
    "plt.colorbar(plot2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All of the variables should be defined earlier, to be certain we are comparing the same things in our plots.\n",
    "RES = 1028\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "Temps4 = torch.zeros((RES**2,3))\n",
    "\n",
    "x = torch.linspace(-5,5,RES)\n",
    "Temps4[:,:2] = torch.cartesian_prod(x, x)\n",
    "probs = torch.zeros((RES**2, 5)).to(DEVICE)\n",
    "\n",
    "\n",
    "#print(distributions[i].log_prob(Temps4[:,0:2]).shape)\n",
    "sfm = torch.nn.Softmax(dim = -1)\n",
    "\n",
    "VAL = torch.zeros((RES**2,5)).to(DEVICE)\n",
    "for i in range(len(distrib)):\n",
    "    VAL[:,i] = distrib[i].log_prob(Temps4[:,0:2]) #Does the log_prob method really do exactly what I want?\n",
    "\n",
    "VAL2 = torch.zeros((RES**2,5)).to(DEVICE)\n",
    "VAL2 = sfm(VAL)\n",
    "#mc = torch.min(VAL,dim = 1).values    \n",
    "#nc = torch.sum(VAL-mc,dim = 1)\n",
    "\n",
    "      \n",
    "#for i in range(len(distrib)):\n",
    "#    VAL[:,i] =  VAL[:,i]-mc)/nc[i]\n",
    "    \n",
    "Temps4[:,2] = -torch.sum(torch.log(VAL2) * VAL2,dim = 1) #We don't log the probs here, since they were already logged.\n",
    "\n",
    "\n",
    "#print(VAL.shape)\n",
    "#print(torch.exp(net3(Temps2[:,0:2])).shape)\n",
    "print(max(torch.exp(distrib[i].log_prob(Temps4[:,0:2]))),min(torch.exp(distrib[i].log_prob(Temps4[:,0:2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8862240",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('True Uncertainty Plot')\n",
    "#xy = [0,0.2,0.4,0.6,0.8,1]\n",
    "#z = xy\n",
    "plot4 = plt.scatter(Temps4[:,0].detach().numpy(), Temps4[:,1].detach().numpy(), s=221000/(RES**2), c=Temps4[:,2].detach().numpy(), cmap='RdYlBu', marker='s')\n",
    "plt.gcf().set_size_inches((14, 12))\n",
    "plt.colorbar(plot4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879386ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net4.state_dict()\n",
    "#print(net4.state_dict()['layers.3.weight_mu'])\n",
    "#get a bar for the range of the entropy scalar.\n",
    "#Center data around 0.\n",
    "\n",
    "#Simuler marginalfordeling for en vekt fra vMF. OG sammenlign med en marginal vekt fra multivariat Gaussisk som har blitt normalisert.\n",
    "#og hva skjer i posterioren etter det er trent. trekk vekter fra HU, gjør forwardpass predictions som simulert data, tren på det og sjekk om vektene blir som i starten.\n",
    "#Hva med å initialisere fra HU!!!???\n",
    "\n",
    "#Siden W_kappa initialiseres så høyt, er det jo ikke så rart at vMF-en generelt er mye mindre selvsikker enn den Gaussiske.\n",
    "#Da er det også forståelig, at ettersom vi øker w_kappa, så må vi også øke læringsraten, siden forandringen i likelihood\n",
    "#loss ved weight_mu justering blir mindre intens. Kanskje er også noe av grunnen til at vi blir tvunget til så høye kappa,\n",
    "#At nettet ikke klarer å finne noen gradient descent ellers? Siden hvis vi er langt unna der W-mu skulle vært, så får vi nesten\n",
    "#ikke noen forandring i loss? Hva med en tostegs-trening, hvor vi først trener med høy kappa. Og så initialiserer vi fra de foregående\n",
    "#W og b muene, men med nye tilfeldige kappa som er mye mindre?? Det høres ut som en god ide!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ee75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "DATA = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00448/carbon_nanotubes.csv',sep = ';', decimal=\",\")\n",
    "#This is the carbon nanotubes data.\n",
    "DATA = DATA.astype(float)\n",
    "#print(DATA)\n",
    "#print(DATA)\n",
    "DATA = DATA.to_numpy()\n",
    "DATA = torch.from_numpy(DATA)\n",
    "#print(DATA)\n",
    "np.random.seed(42069)\n",
    "#torch.manual_seed(42069)\n",
    "\n",
    "DATA = DATA.type(torch.float32)\n",
    "\n",
    "data_mean = DATA.mean(axis=1)[0:8]\n",
    "data_std = DATA.std(axis=1)[0:8]\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "\n",
    "#DATA[:,7] = 5*DATA[:,1] + 3*DATA[:,6] + 2*DATA[:,3] + 1*DATA[:,2] \n",
    "DATA[:,0:8] = (DATA[:,0:8]  - data_mean)/data_std\n",
    "#print('DATA normalized:',DATA,'len(DATA) normalized:',len(DATA),'mean dtrain normalized:',DATA.mean(axis=0)[2])\n",
    "tr_ids = np.random.choice(10721, 6000, replace = False)\n",
    "\n",
    "dTRAIN_CARBON = DATA[tr_ids,:]\n",
    "dTEST_CARBON = DATA[-tr_ids,:]\n",
    "\n",
    "print(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa13ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import time\n",
    "import mpmath\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "COND_OPT = False\n",
    "CLASSES = 1\n",
    "# TRAIN_EPOCHS = 250\n",
    "SAMPLES = 1\n",
    "TEST_SAMPLES = 10\n",
    "TEMPER = 0.001\n",
    "TEMPER_PRIOR = 0.001\n",
    "pepochs = 30\n",
    "epochs =10\n",
    "TEST_BATCH_SIZE = 6000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "import test_ensemble\n",
    "importlib.reload(test_ensemble)\n",
    "import FVMF\n",
    "importlib.reload(FVMF)\n",
    "\n",
    "data_shape = (0,7,7,8)\n",
    "l1shape=(7, 7)\n",
    "l2shape=(7, 7)\n",
    "l3shape=(7, 7)\n",
    "l4shape=(7, 1)\n",
    "layershapes = [l1shape, l2shape, l3shape, l4shape]\n",
    "\n",
    "trtimes  = np.zeros(epochs)\n",
    "\n",
    "\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net5= FVMF.BayesianNetwork(#w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dTRAIN_CARBON, dtest=dTEST_CARBON,\n",
    "                                VD='Gaussian',\n",
    "                                #b_kappa=torch.Tensor(1).uniform_(3,3.1),\n",
    "                                #w_kappa=torch.Tensor(1).uniform_(5,5.1),\n",
    "                                Temper = 0.1,\n",
    "                                classification='Regression')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net5.parameters(), lr=0.0007)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net5, dTRAIN_CARBON, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100,\n",
    "                                    shape = data_shape,CLASSES = 1)\n",
    "        #print('max:',net4.weight_mu[1].max())\n",
    "        #print('norm:',torch.norm(net4.weight_mu[1]))\n",
    "\n",
    "    loss, outputs, output = test_ensemble.test_ensemble(net5,dTEST_CARBON,TEST_SAMPLES,TEST_BATCH_SIZE,TEST_BATCH_SIZE,\n",
    "                                      CLASSES,DEVICE,shape = data_shape,classification = False,plot = True)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50521eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import time\n",
    "import mpmath\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "COND_OPT = False\n",
    "CLASSES = 1\n",
    "# TRAIN_EPOCHS = 250\n",
    "SAMPLES = 1\n",
    "TEST_SAMPLES = 10\n",
    "TEMPER = 0.001\n",
    "TEMPER_PRIOR = 0.001\n",
    "pepochs = 30\n",
    "epochs = 8\n",
    "TEST_BATCH_SIZE = 6000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "import test_ensemble\n",
    "importlib.reload(test_ensemble)\n",
    "import FVMF\n",
    "importlib.reload(FVMF)\n",
    "\n",
    "data_shape = (0,7,7,8)\n",
    "l1shape=(7, 7)\n",
    "l2shape=(7, 7)\n",
    "l3shape=(7, 7)\n",
    "l4shape=(7, 1) #So the vMF mathematically does not support having a layer that ends in 1. This is the cause of the bug.\n",
    "#However, should we even have the last layer as a vmf for regression? I don't really think so. Lets try the layerwise vmf\n",
    "#for the last one. Wait... why is the layerwise x_dim=out*in for its weights while the nodewise is just x_dim=in? Yeah cause I\n",
    "#list stuff together inside the vmf_nodewise, so that it makes sense. Maybe it will work better to just have a frequenstist last layer?\n",
    "#The loss is not calculated correctly, MSE criterion 0.92, is not representative of the network missing by 42000 on a 0-1 regression task.\n",
    "#There was some PyTorch funny business with the lr being so low that the los becomes jumpy and the pedictions rubbish.... No\n",
    "#immediate mathematical interpretation of this strange behaviour as far as I can see, so I think it is a technical probelm\n",
    "#with regard to loss or gradient calculation in the PyTorch machinery.\n",
    "\n",
    "#But bro if the out_features are 1, then in=out*in! So the layerwise vmf won't help you. Let's do Gaussian.\n",
    "layershapes = [l1shape, l2shape, l3shape, l4shape]\n",
    "\n",
    "trtimes  = np.zeros(epochs)\n",
    "\n",
    "\n",
    "#Note, for this regression task, the last 7 to 1 layer has a Gaussian VD, where we kill the prior and simply optimize with MLE.\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    vMFRegression= FVMF.BayesianNetwork(#w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dTRAIN_CARBON, dtest=dTEST_CARBON,\n",
    "                                VD='vmf',\n",
    "                                b_kappa=torch.Tensor(1).uniform_(3,3.1),\n",
    "                                w_kappa=torch.Tensor(1).uniform_(7.5,7.6),\n",
    "                                Temper = 0,classification='Regression',NODEFORCE =False)\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(vMFRegression.parameters(), lr=0.11)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(vMFRegression, dTRAIN_CARBON, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100,\n",
    "                                    shape = data_shape,CLASSES = 1)\n",
    "        print('max:',vMFRegression.weight_mu[1].max())\n",
    "        print('norm:',torch.norm(vMFRegression.weight_mu[1]))\n",
    "\n",
    "    loss, outputs, output = test_ensemble.test_ensemble(vMFRegression,dTEST_CARBON,TEST_SAMPLES,TEST_BATCH_SIZE,TEST_BATCH_SIZE,\n",
    "                                      CLASSES,DEVICE,shape = data_shape,classification = False,plot = True)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f99831",
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_intensity = 1\n",
    "\n",
    "#Kanskje er det en god idee å også arve kappaene, men halvere dem? Hva om vi også kjører på med litt normalizering av mu-ene her?\n",
    "#Hva med adaptiv kappa per lag? Det er jo bare en kappa per bias-lag. GC fungerer rett og slett ikke.\n",
    "\n",
    "w_mu_R = []\n",
    "for i in range(len(vMFRegression.weight_mu)):\n",
    "    #print('\\n','torch.norm(net4.weight_mu[i]):',torch.norm(net4.weight_mu[i]))\n",
    "    w_mu_R.append(vMFRegression.weight_mu[i]/torch.norm(vMFRegression.weight_mu[i]))\n",
    "    #print('\\n','norm w_mu[i]',torch.norm(w_mu[i]))\n",
    "    \n",
    "b_mu_R = []\n",
    "for i in range(len(vMFRegression.bias_mu)):\n",
    "    #print('\\n','torch.norm(net4.bais_mu[i]):',torch.norm(net4.bias_mu[i]))\n",
    "    b_mu_R.append(vMFRegression.bias_mu[i]/torch.norm(vMFRegression.bias_mu[i]))\n",
    "    #print('\\n','norm b_mu[i]',torch.norm(b_mu[i]))\n",
    "    \n",
    "#For some reason, it seems that the weights are not being properly normalized here. I don't know why that is.\n",
    "\n",
    "r\"\"\"\n",
    "Bruh! Remember the rho's!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f22dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    vMFRegression2= FVMF.BayesianNetwork(w_mu = w_mu_R, b_mu = b_mu_R, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dTRAIN_CARBON, dtest=dTEST_CARBON,\n",
    "                                VD='vmf',\n",
    "                                b_kappa= b_rho, #torch.Tensor(1).uniform_(1.0,3.1), \n",
    "                                w_kappa= w_rho, #torch.Tensor(1).uniform_(2.0,4.1), \n",
    "                                Temper = 1,classification = 'regression')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(vMFRegression2.parameters(), lr=0.05)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(vMFRegression2, dTRAIN_CARBON, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100,\n",
    "                                    shape = data_shape,CLASSES = 1)\n",
    "        print('max:',vMFRegression2.weight_mu[1].max())\n",
    "        print('norm:',torch.norm(vMFRegression2.weight_mu[1]))\n",
    "\n",
    "    loss, outputs, output = test_ensemble.test_ensemble(vMFRegression2,dTEST_CARBON,TEST_SAMPLES,TEST_BATCH_SIZE,TEST_BATCH_SIZE,\n",
    "                                      CLASSES,DEVICE,shape = data_shape,classification = False,plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379109ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = [0,1,2,3,4,5]\n",
    "for i,G, in enumerate(g):\n",
    "    print('i:',i,'g:',G)\n",
    "print(len(g))\n",
    "i,j = True,True\n",
    "if (i==1) or (j==1):\n",
    "    print('The or statement in Python means and/or')\n",
    "else:\n",
    "    print('The or statement in Python means either or')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d295471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The RSS doesn't really vary much based on the number of epochs I administer. I suspect this to be either because we are not\n",
    "#training the network correctly, or we are testing it incorrectly.\n",
    "\n",
    "#Make many forward passes, and calculate the MSE on all of the forward passes!\n",
    "\n",
    "#Also calculate the percentiles for them!\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torchvision.datasets as datasets\n",
    "import os\n",
    "\n",
    "cifar_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "cifar_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72f33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(transforms.ToTensor(cifar_train))\n",
    "print(cifar_train[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dbc2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok so this is actually not trivial... Maybe we need to place a convulutional layer first in order to properly parse this into\n",
    "#our vMF so that we don't lose the positionality of our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3241c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "What if the problem is that since the mu's in the Gaussian is (out,in), and the vMF is out*in,\n",
    "this could mean that we have \"strethed\" a single vMF pdf over all the parameters, while in the Gaussian we have made one for each output?\n",
    "\n",
    "I don't know, also intuitively this should be the case, since the whole point of the vMF is the norm 1, which obviously\n",
    "will require that it for each forward-pass is only one massive pdf for all inputs and outputs.\n",
    "\n",
    "Ok, this can get rough, I will try my best to reshape the w_mu's and b_mu's the best I can, perhaps this will work just fine without too much tuning...\n",
    "Hopefully.\n",
    "\n",
    "This doe not seem to ave worked. I don't konw exactly what the problem is. Per haps it is a good idea to consult the new loss function\n",
    "suggested in the paper that made the code we based our vMF on?\n",
    "\n",
    "It is very strange that the loss is not at all affected by completely ridiculous learning rates...\n",
    "\n",
    "Remember that vMF makes the norm of the weights and biases 1, not the forward pass of the x's. Hence the advantage is that the gradient\n",
    "will not explode, since the backward pass of it will also be approx. 1. In batchnorm, maybe the gradient can explode? Since the weights \n",
    "can be whatever?\n",
    "\n",
    "\n",
    "IMPORTANT: The gaussian neuralnet will also collapse to 257 if I apply more than 3 layers. This must be somehow related to the similar\n",
    "behavior in the vMF when the size of each layer exceeds 3. Per haps there is an error in the loss afterall?\n",
    "However, in the Gaussian case, increasing the learning rate by a factor of 10 solved the issue. This makes me suspect it is the mathematical\n",
    "properties of the loss function, rather than incorrect implementation.\n",
    "\"\"\"\n",
    "\n",
    "#When l4 is (3,5):\n",
    "r\"\"\"\n",
    "File ~/projects/BNN/AliaksandrFolder/FVMF.py:289, in vMF.sample(self, N, rsf)\n",
    "    287 e1mu = torch.zeros(d, 1).to(DEVICE)\n",
    "    288 e1mu[0, 0] = 1.0\n",
    "--> 289 e1mu = e1mu - self.mu if len(self.mu.shape) == 2 else e1mu - self.mu.unsqueeze(1) #e1mu.shape = (1,self.x_dim). mu_unnorm.shape = (mu_unnorm)\n",
    "    290 e1mu = e1mu / norm(e1mu, dim=0).to(DEVICE)\n",
    "    291 samples = samples - 2 * (samples @ e1mu) @ e1mu.t()\n",
    "\n",
    "RuntimeError: The size of tensor a (15) must match the size of tensor b (9) at non-singleton dimension 0\n",
    "\"\"\"\n",
    "\n",
    "#When l4 is (5,5):\n",
    "r\"\"\"\n",
    "File ~/projects/BNN/AliaksandrFolder/FVMF.py:289, in vMF.sample(self, N, rsf)\n",
    "    287 e1mu = torch.zeros(d, 1).to(DEVICE)\n",
    "    288 e1mu[0, 0] = 1.0\n",
    "--> 289 e1mu = e1mu - self.mu if len(self.mu.shape) == 2 else e1mu - self.mu.unsqueeze(1) #e1mu.shape = (1,self.x_dim). mu_unnorm.shape = (mu_unnorm)\n",
    "    290 e1mu = e1mu / norm(e1mu, dim=0).to(DEVICE)\n",
    "    291 samples = samples - 2 * (samples @ e1mu) @ e1mu.t()\n",
    "\n",
    "RuntimeError: The size of tensor a (25) must match the size of tensor b (15) at non-singleton dimension 0\n",
    "\"\"\"\n",
    "#These errors above were caused by my initialization being wrong. I copy paster mu_3 for layer4, and forgot to change to mu_4. So now \n",
    "#I always get the error below.\n",
    "\n",
    "\n",
    "#in all cases now: \n",
    "\n",
    "r\"\"\"\n",
    "It seems that the whole thing does not progress at all. We just get the warning and then no further output.\n",
    "\n",
    "self.l4(x, sample)\n",
    "\n",
    "--> self.bias.sample()\n",
    "\n",
    "It always get's stuck there!!\n",
    "\n",
    "Specifically, it get's stuck in the while loop:\n",
    "\n",
    "while len(v0) < N:\n",
    "            eps = beta.sample([1, rsf * (N - len(v0))]).squeeze().to(DEVICE)\n",
    "            uns = uniform.sample([1, rsf * (N - len(v0))]).squeeze().to(DEVICE)\n",
    "            w0 = (1 - (1 + bb) * eps) / (1 - (1 - bb) * eps)\n",
    "            t0 = (2 * aa * bb) / (1 - (1 - bb) * eps)\n",
    "            det = (d - 1) * t0.log() - t0 + dd - uns.log()\n",
    "            v0 = torch.cat([v0, torch.tensor(w0[det >= 0]).to(DEVICE)])\n",
    "            if len(v0) > N:\n",
    "                v0 = v0[:N]\n",
    "                break\n",
    "\"\"\"\n",
    "\n",
    "r\"\"\"\n",
    "From further investigations it is clear that the error lies in w0[det >= 0] consistently being an empty Tensor.\n",
    "\n",
    "Even further, bb is 0 here which it usually is not. That must definitely indicate something is wrong.\n",
    "\n",
    "Adjusting the initialization of kappa to be 9 or less on both weights and biases makes the code run, \n",
    "but posterior collapse is back. Increasing kappa seems to increase the compute aswell... however, getting the kappa inits\n",
    "closer to 10 seems to also help avoid the posterior collapse. And the lower bound increased also helps, looks like 3 is optimal.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "r\"\"\"\n",
    "It seems that Torch likes that each of the bias_mu's and weight_mu's from each layer are separately registered with name as an nn.parameter.\n",
    "\"\"\"\n",
    "\n",
    "r\"\"\"\n",
    "Currently, for 4 layers with 3 hiddenwidth, it seems around 10 epochs with .14 learning rate is optimal for testperformance.\n",
    "I suspect this is because we do not have the modelcapacity to go beyond the overfiting case just yet, and must settle for the classical\n",
    "best-fit.\n",
    "\"\"\"\n",
    "\n",
    "r\"\"\"\n",
    "The problem for both the random initialization and the variable length Gaussian has the same root. It is that the mu's and rho's \n",
    "are not being registered as parameters per layer to begin with!\n",
    "\n",
    "And since this registering works just fine when we are directly assigning self.layer's to be each layer the parameters are registered correctly,\n",
    "it must be the case that this part in the BayesianNetwork's initializer is where the problem originates.\n",
    "\"\"\"\n",
    "\n",
    "r\"\"\"\n",
    "Part of the reason why the layerwise vMF might not be that performant, \n",
    "is that it forces one kappa on every weight in the entire layer.\n",
    "\"\"\"\n",
    "\n",
    "r\"\"\"\n",
    "The way the mu of the weights are used in the vMF is that any mu is accepted, and then the mu's are normalized. \n",
    "I think this is the reason for why the net becomes intractably slow as we increase the layers. \n",
    "If it is possible to set the weight_mu parameters to be the normalized versions for every epoch I think that would be great.\n",
    "\n",
    "Or perhaps build into the loss a term that penalizes the weights from deviating from norm=1...\n",
    "\n",
    "I don't know exactly where to put this\n",
    "\"\"\"\n",
    "\n",
    "r\"\"\"\n",
    "The training function I got from Aliaksandr uses Variable() which is depcrecated since PyTorch 0.4, and creates tensors directly \n",
    "via torch.FloatTensor which is also bad practice. In addition the data is presented to the train function as numpy arrays.\n",
    "\n",
    "All these three issues require resolution.\n",
    "\n",
    "I starred a S.Overflow post that showed what I think will be the solution to the ghost-Mu. Remember that you could motivate this \n",
    "mathematically by proving dF(x/norm(x);parameters)/dx = dF(x;parameters)/dnorm(x)\n",
    "\n",
    "Should I try to see what happens if I use float64 instead?\n",
    "\"\"\"\n",
    "\n",
    "r\"\"\"\n",
    "Should I really have a vMF on the biases? They don't contribute to the gradient much in the backward-pass, \n",
    "making them norm 1 doesn't really make too much sense..\n",
    "\"\"\"\n",
    "\n",
    "r\"\"\"\n",
    "[Kappa is called concentration parameter because the higher the kappa the lower the variance, \n",
    "i.e. the higher the concentration around mu. This also explains why the vMF struggles for higher kappas, \n",
    "because it is known that the vMF is numerically heavy and unstable for high concentrations, aka low variance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2634079",
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Plan:\n",
    "\n",
    "First solve the uncertainty estimation.\n",
    "\n",
    "Solve comparing deeper nets, with alternating use of batchnorm.\n",
    "Solve a couple more image-classification data sets\n",
    "Solve the nn.Parameter(the Mu's) normalization business.\n",
    "Solve having separate kappas for each dimension of the vMF. (I probably won't get to this..)\n",
    "\n",
    "Compare with FNN's?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(42069)\n",
    "torch.manual_seed(42069)\n",
    "\n",
    "PL = [torch.Tensor([1-3, 1-3]),torch.Tensor([5-3, 1-3]),torch.Tensor([1-3, 5-3]),torch.Tensor([5-3, 5-3]),torch.Tensor([3-3, 3-3])]\n",
    "cov = torch.eye(2)\n",
    "n = 150\n",
    "\n",
    "plt.figure(figsize=(10, 10), dpi=500)\n",
    "\n",
    "DF = torch.zeros((len(PL),n,1,3)) #multiple of 4\n",
    "for i, MU in enumerate(PL): #enumerate starts from and including 0.\n",
    "    distrib = torch.distributions.MultivariateNormal(loc=MU, covariance_matrix=cov)\n",
    "    DATA_ = distrib.sample((n,1))\n",
    "\n",
    "    DATA  = torch.zeros([n, 1, 3])\n",
    "    DATA[:,:,:2] = DATA_\n",
    "    DATA[:,:,2]  = i\n",
    "    DF[i,:,:,:] = DATA\n",
    "    \n",
    "    x = DATA[:,0,0]\n",
    "    y = DATA[:,0,1]\n",
    "    plt.plot(x,y,'.',markersize=1.25)\n",
    "plt.show()\n",
    "\n",
    "C = int(3*n/4)\n",
    "\n",
    "#DATA_train = torch.zeros((len(PL)*C,3))\n",
    "#DATA_test = torch.zeros((len(PL)*(n-C),3))\n",
    "\n",
    "DATA = DF.reshape(len(PL)*n,3)\n",
    "#print('DATA:',DATA,'len(DATA):',len(DATA),'mean dtrain:',DATA.mean(axis=0)[2])\n",
    "\n",
    "#data_mean = DATA.mean(axis=1)[0:2]\n",
    "#data_std = DATA.std(axis=1)[0:2]\n",
    "\n",
    "#DATA[:,0:2] = (DATA[:,0:2]  - data_mean)/data_std\n",
    "#print('DATA normalized:',DATA,'len(DATA) normalized:',len(DATA),'mean dtrain normalized:',DATA.mean(axis=0)[2])\n",
    "tr_ids = np.random.choice(n*5, n*4, replace = False)\n",
    "\n",
    "\n",
    "\n",
    "dtrain = DATA[tr_ids,:]\n",
    "dtest = DATA[-tr_ids,:]\n",
    "\n",
    "#print('\\n','dtrain:',dtrain, 'len(dtrain):',len(dtrain),'mean dtrain:',dtrain.mean(axis=0)[2])\n",
    "#print('\\n','dtest:',dtest, 'len(dtest):',len(dtest),'mean dtest:',dtest.mean(axis=0)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb74d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import time\n",
    "import mpmath\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "\n",
    "import test_ensemble\n",
    "importlib.reload(test_ensemble)\n",
    "import FVMF\n",
    "importlib.reload(FVMF)\n",
    "\n",
    "# define the summary writer\n",
    "writer = SummaryWriter()\n",
    "# select the device\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "cuda = torch.cuda.set_device(1)\n",
    "\n",
    "# define the parameters\n",
    "\n",
    "COND_OPT = False\n",
    "CLASSES = 5\n",
    "# TRAIN_EPOCHS = 250\n",
    "SAMPLES = 1\n",
    "TEST_SAMPLES = 10\n",
    "TEMPER = 0.001\n",
    "TEMPER_PRIOR = 0.001\n",
    "pepochs = 50\n",
    "TEST_BATCH_SIZE = 100\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "l1shape=(2, 5)\n",
    "l2shape=(5, 5)\n",
    "l3shape=(5, 5)\n",
    "l4shape=(5, 5)\n",
    "l5shape=(5, 5)\n",
    "l6shape=(5, 5)\n",
    "layershapes = [l1shape, l2shape, l3shape, l4shape]\n",
    "\n",
    "# set prior parameters\n",
    "PI = 1\n",
    "SIGMA_1 = torch.cuda.FloatTensor([math.exp(-0)])\n",
    "SIGMA_2 = torch.cuda.FloatTensor([math.exp(-6)])\n",
    "data_shape = (0,2,2,3)\n",
    "\n",
    "epochs = 30\n",
    "trtimes  = np.zeros(epochs)\n",
    "#w_mu = [w_mu1, w_mu2, w_mu3, w_mu4]\n",
    "#b_mu = [b_mu1, b_mu2, b_mu3, b_mu4]\n",
    "\n",
    "#w_mu_nodewise = [w_mu1_nodewise,w_mu2_nodewise,w_mu3_nodewise,w_mu4_nodewise]\n",
    "#b_mu_nodewise = [b_mu1_nodewise,b_mu2_nodewise,b_mu3_nodewise,b_mu4_nodewise]\n",
    "# make inference on 10 networks\n",
    "\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net3 = FVMF.BayesianNetwork(#w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='Gaussian',\n",
    "                                #b_kappa=torch.Tensor(1).uniform_(4,4.1),\n",
    "                                #w_kappa=torch.Tensor(1).uniform_(6,6.1),\n",
    "                                Temper = 1,classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net3.parameters(), lr=0.04)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net3, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100, shape = data_shape)\n",
    "        print('max:',net3.weight_mu[1].max())\n",
    "        print('norm:',torch.norm(net3.weight_mu[1]))\n",
    "\n",
    "    res = test_ensemble.test_ensemble(net3,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = data_shape)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6139cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_ensemble\n",
    "importlib.reload(test_ensemble)\n",
    "import FVMF\n",
    "importlib.reload(FVMF)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net4 = FVMF.BayesianNetwork(#w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa=torch.Tensor(1).uniform_(4.0,4.1),\n",
    "                                w_kappa=torch.Tensor(1).uniform_(6.0,6.1),\n",
    "                                Temper = 1,classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net4.parameters(), lr=0.14)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net4, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100, shape = data_shape)\n",
    "        #print('max:',net4.weight_mu[1].max())\n",
    "        #print('norm:',torch.norm(net4.weight_mu[1]))\n",
    "\n",
    "    #res = test_ensemble.test_ensemble(net4,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = data_shape)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09481e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_intensity = 1\n",
    "\n",
    "#Kanskje er det en god idee å også arve kappaene, men halvere dem? Hva om vi også kjører på med litt normalizering av mu-ene her?\n",
    "#Hva med adaptiv kappa per lag? Det er jo bare en kappa per bias-lag.\n",
    "\n",
    "w_mu = []\n",
    "for i in range(len(net4.weight_mu)):\n",
    "    #print('\\n','torch.norm(net4.weight_mu[i]):',torch.norm(net4.weight_mu[i]))\n",
    "    w_mu.append(net4.weight_mu[i]/torch.norm(net4.weight_mu[i]))\n",
    "    #print('\\n','norm w_mu[i]',torch.norm(w_mu[i]))\n",
    "    \n",
    "b_mu = []\n",
    "for i in range(len(net4.bias_mu)):\n",
    "    #print('\\n','torch.norm(net4.bais_mu[i]):',torch.norm(net4.bias_mu[i]))\n",
    "    b_mu.append(net4.bias_mu[i]/torch.norm(net4.bias_mu[i]))\n",
    "    #print('\\n','norm b_mu[i]',torch.norm(b_mu[i]))\n",
    "    \n",
    "b_rho= []\n",
    "for i in range(len(net4.bias_rho)):\n",
    "    b_rho.append(net4.bias_rho[i]*GC_intensity)\n",
    "\n",
    "w_rho= []\n",
    "for i in range(len(net4.weight_rho)):\n",
    "    w_rho.append(net4.weight_rho[i]*GC_intensity)\n",
    "\n",
    "#print('b_rho:',b_rho, '\\n','w_rho:',b_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698a0b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net4_GC = FVMF.BayesianNetwork(w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa= b_rho, #torch.Tensor(1).uniform_(1.0,3.1), \n",
    "                                w_kappa= w_rho, #torch.Tensor(1).uniform_(2.0,4.1), \n",
    "                                Temper = 1,classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net4_GC.parameters(), lr=0.07)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net4_GC, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100, shape = data_shape)\n",
    "        #print('max:',net4.weight_mu[1].max())\n",
    "        #print('norm:',torch.norm(net4.weight_mu[1]))\n",
    "\n",
    "    #res = test_ensemble.test_ensemble(net4_GC,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = data_shape)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")\n",
    "#print('This is the loss with the Gradient Capture method/Normalized Initialization Inheritance')\n",
    "\n",
    "#Ok, så kanskje drit i gradient-capture-method. Men! Husk hva du har vist her nå med kun normalisering av vektene, Du får trent nettet\n",
    "#Videre, og det fungerer faktisk. I tilfellet hvor du ikke gjør det ender du faktisk ikke bare opp med dårlig ytelse, men\n",
    "#hele nettet brekker!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593138c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_intensity = 1\n",
    "\n",
    "#Kanskje er det en god idee å også arve kappaene, men halvere dem? Hva om vi også kjører på med litt normalizering av mu-ene her?\n",
    "#Hva med adaptiv kappa per lag? Det er jo bare en kappa per bias-lag. GC fungerer rett og slett ikke.\n",
    "\n",
    "w_mu = []\n",
    "for i in range(len(net4_GC.weight_mu)):\n",
    "    #print('\\n','torch.norm(net4.weight_mu[i]):',torch.norm(net4.weight_mu[i]))\n",
    "    w_mu.append(net4_GC.weight_mu[i]/torch.norm(net4_GC.weight_mu[i]))\n",
    "    #print('\\n','norm w_mu[i]',torch.norm(w_mu[i]))\n",
    "    \n",
    "b_mu = []\n",
    "for i in range(len(net4_GC.bias_mu)):\n",
    "    #print('\\n','torch.norm(net4.bais_mu[i]):',torch.norm(net4.bias_mu[i]))\n",
    "    b_mu.append(net4_GC.bias_mu[i]/torch.norm(net4_GC.bias_mu[i]))\n",
    "    #print('\\n','norm b_mu[i]',torch.norm(b_mu[i]))\n",
    "    \n",
    "b_rho= []\n",
    "for i in range(len(net4_GC.bias_rho)):\n",
    "    b_rho.append(net4_GC.bias_rho[i]*GC_intensity)\n",
    "\n",
    "w_rho= []\n",
    "for i in range(len(net4_GC.weight_rho)):\n",
    "    w_rho.append(net4_GC.weight_rho[i]*GC_intensity)\n",
    "\n",
    "#print('b_rho:',b_rho, '\\n','w_rho:',b_mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ac231",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net4_GC2 = FVMF.BayesianNetwork(w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa= b_rho, #torch.Tensor(1).uniform_(1.0,3.1), \n",
    "                                w_kappa= w_rho, #torch.Tensor(1).uniform_(2.0,4.1), \n",
    "                                Temper = 1,classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net4_GC2.parameters(), lr=0.035)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net4_GC2, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100, shape = data_shape)\n",
    "        #print('max:',net4.weight_mu[1].max())\n",
    "        #print('norm:',torch.norm(net4.weight_mu[1]))\n",
    "\n",
    "    res = test_ensemble.test_ensemble(net4_GC2,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = data_shape)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")\n",
    "print('This is the loss with the Gradient Capture method/Normalized Initialization Inheritance, applied twice')\n",
    "\n",
    "#Ok, så kanskje drit i gradient-capture-method. Men! Husk hva du har vist her nå med kun normalisering av vektene, Du får trent nettet\n",
    "#Videre, og det fungerer faktisk. I tilfellet hvor du ikke gjør det ender du faktisk ikke bare opp med dårlig ytelse, men\n",
    "#hele nettet brekker!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9932a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES = 1028 #Ca. Full HD resolution. If you struggle with memory adjust this parameter down. 64 for example already gives a decent view.\n",
    "enums = 10\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "Temps = torch.zeros((RES**2,3))\n",
    "i, j = 0, 0\n",
    "\n",
    "x = torch.linspace(-5,5,RES)\n",
    "\n",
    "Temps[:,:2] = torch.cartesian_prod(x, x)\n",
    "probs = torch.zeros((1,5)).to(DEVICE)\n",
    "\n",
    "for j in range(enums):\n",
    "    probs = probs + torch.exp(net4_GC2(Temps[:,0:2])) #This is done enums times, each one will be different due to stochastic.\n",
    "probs = probs/enums\n",
    "\n",
    "Temps[:,2] = -torch.sum(probs * torch.log(probs),dim = 1)\n",
    "print(torch.max(Temps[:,2]),torch.min(Temps[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a9fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('vMF Uncertainty Plot 42epocsLR0.1 3*10epocs, NII in between.')\n",
    "#xy = [0,0.2,0.4,0.6,0.8,1]\n",
    "#z = xy\n",
    "plot = plt.scatter(Temps[:,0].detach().numpy(), Temps[:,1].detach().numpy(),vmin = 0, vmax = 1.4, s=221000/(RES**2), c=Temps[:,2].detach().numpy(), cmap='RdYlBu', marker='s')\n",
    "plt.gcf().set_size_inches((14, 12))\n",
    "plt.colorbar(plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43a9faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RES = 1028\n",
    "enums = 10\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "Temps2 = torch.zeros((RES**2,3))\n",
    "i, j = 0, 0\n",
    "\n",
    "x = torch.linspace(-5,5,RES)\n",
    "\n",
    "Temps2[:,:2] = torch.cartesian_prod(x, x)\n",
    "probs = torch.zeros((1,5)).to(DEVICE)\n",
    "\n",
    "for j in range(enums):\n",
    "    probs = probs + torch.exp(net3(Temps2[:,0:2])) #This is done enums times, each one will be different due to stochastic.\n",
    "probs = probs/enums\n",
    "\n",
    "Temps2[:,2] = -torch.sum(probs * torch.log(probs),dim = 1)\n",
    "print(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1bfba7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title('Gaussian Uncertainty Plot')\n",
    "#xy = [0,0.2,0.4,0.6,0.8,1]\n",
    "#z = xy\n",
    "plot2 = plt.scatter(Temps2[:,0].detach().numpy(), Temps2[:,1].detach().numpy(),vmin = 0, vmax = 1.4, s=221000/(RES**2), c=Temps2[:,2].detach().numpy(), cmap='RdYlBu', marker='s')\n",
    "plt.gcf().set_size_inches((14, 12))\n",
    "plt.colorbar(plot2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a318b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "RES = 1028\n",
    "enums = 10\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "Temps2 = torch.zeros((RES**2,3))\n",
    "i, j = 0, 0\n",
    "\n",
    "x = torch.linspace(-5,5,RES)\n",
    "\n",
    "Temps2[:,:2] = torch.cartesian_prod(x, x)\n",
    "probs = torch.zeros((1,5)).to(DEVICE)\n",
    "\n",
    "for j in range(enums):\n",
    "    probs = probs + torch.exp(net3(Temps2[:,0:2])) #This is done enums times, each one will be different due to stochastic.\n",
    "probs = probs/enums\n",
    "\n",
    "Temps2[:,2] = -torch.sum(probs * torch.log(probs),dim = 1)\n",
    "print(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4db301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(42069)\n",
    "torch.manual_seed(42069)\n",
    "\n",
    "PL = [torch.Tensor([1-3, 1-3]),torch.Tensor([5-3, 1-3]),torch.Tensor([1-3, 5-3]),torch.Tensor([5-3, 5-3]),torch.Tensor([3-3, 3-3])]\n",
    "cov = torch.eye(2)\n",
    "n = 50\n",
    "\n",
    "plt.figure(figsize=(10, 10), dpi=500)\n",
    "\n",
    "DF = torch.zeros((len(PL),n,1,3)) #multiple of 4\n",
    "for i, MU in enumerate(PL): #enumerate starts from and including 0.\n",
    "    distrib = torch.distributions.MultivariateNormal(loc=MU, covariance_matrix=cov)\n",
    "    DATA_ = distrib.sample((n,1))\n",
    "\n",
    "    DATA  = torch.zeros([n, 1, 3])\n",
    "    DATA[:,:,:2] = DATA_\n",
    "    DATA[:,:,2]  = i\n",
    "    DF[i,:,:,:] = DATA\n",
    "    \n",
    "    x = DATA[:,0,0]\n",
    "    y = DATA[:,0,1]\n",
    "    plt.plot(x,y,'.',markersize=1.25)\n",
    "plt.show()\n",
    "\n",
    "C = int(3*n/4)\n",
    "\n",
    "#DATA_train = torch.zeros((len(PL)*C,3))\n",
    "#DATA_test = torch.zeros((len(PL)*(n-C),3))\n",
    "\n",
    "DATA = DF.reshape(len(PL)*n,3)\n",
    "#print('DATA:',DATA,'len(DATA):',len(DATA),'mean dtrain:',DATA.mean(axis=0)[2])\n",
    "\n",
    "#data_mean = DATA.mean(axis=1)[0:2]\n",
    "#data_std = DATA.std(axis=1)[0:2]\n",
    "\n",
    "#DATA[:,0:2] = (DATA[:,0:2]  - data_mean)/data_std\n",
    "#print('DATA normalized:',DATA,'len(DATA) normalized:',len(DATA),'mean dtrain normalized:',DATA.mean(axis=0)[2])\n",
    "tr_ids = np.random.choice(n*5, n*4, replace = False)\n",
    "\n",
    "\n",
    "\n",
    "dtrain = DATA[tr_ids,:]\n",
    "dtest = DATA[-tr_ids,:]\n",
    "\n",
    "#print('\\n','dtrain:',dtrain, 'len(dtrain):',len(dtrain),'mean dtrain:',dtrain.mean(axis=0)[2])\n",
    "#print('\\n','dtest:',dtest, 'len(dtest):',len(dtest),'mean dtest:',dtest.mean(axis=0)[2])\n",
    "\n",
    "import math\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import time\n",
    "import mpmath\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "\n",
    "import test_ensemble\n",
    "importlib.reload(test_ensemble)\n",
    "import FVMF\n",
    "importlib.reload(FVMF)\n",
    "\n",
    "# define the summary writer\n",
    "writer = SummaryWriter()\n",
    "# select the device\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "cuda = torch.cuda.set_device(1)\n",
    "\n",
    "# define the parameters\n",
    "\n",
    "COND_OPT = False\n",
    "CLASSES = 5\n",
    "# TRAIN_EPOCHS = 250\n",
    "SAMPLES = 1\n",
    "TEST_SAMPLES = 10\n",
    "TEMPER = 0.001\n",
    "TEMPER_PRIOR = 0.001\n",
    "pepochs = 50\n",
    "TEST_BATCH_SIZE = 100\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "l1shape=(2, 5)\n",
    "l2shape=(5, 5)\n",
    "l3shape=(5, 5)\n",
    "l4shape=(5, 5)\n",
    "l5shape=(5, 5)\n",
    "l6shape=(5, 5)\n",
    "layershapes = [l1shape, l2shape, l3shape, l4shape]\n",
    "\n",
    "# set prior parameters\n",
    "PI = 1\n",
    "SIGMA_1 = torch.cuda.FloatTensor([math.exp(-0)])\n",
    "SIGMA_2 = torch.cuda.FloatTensor([math.exp(-6)])\n",
    "data_shape = (0,2,2,3)\n",
    "\n",
    "epochs = 30\n",
    "trtimes  = np.zeros(epochs)\n",
    "#w_mu = [w_mu1, w_mu2, w_mu3, w_mu4]\n",
    "#b_mu = [b_mu1, b_mu2, b_mu3, b_mu4]\n",
    "\n",
    "#w_mu_nodewise = [w_mu1_nodewise,w_mu2_nodewise,w_mu3_nodewise,w_mu4_nodewise]\n",
    "#b_mu_nodewise = [b_mu1_nodewise,b_mu2_nodewise,b_mu3_nodewise,b_mu4_nodewise]\n",
    "# make inference on 10 networks\n",
    "\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net3 = FVMF.BayesianNetwork(#w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='Gaussian',\n",
    "                                #b_kappa=torch.Tensor(1).uniform_(4,4.1),\n",
    "                                #w_kappa=torch.Tensor(1).uniform_(6,6.1),\n",
    "                                Temper = 1,classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net3.parameters(), lr=0.04)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net3, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100, shape = data_shape)\n",
    "        print('max:',net3.weight_mu[1].max())\n",
    "        print('norm:',torch.norm(net3.weight_mu[1]))\n",
    "\n",
    "    res = test_ensemble.test_ensemble(net3,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = data_shape)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")\n",
    "\n",
    "import test_ensemble\n",
    "importlib.reload(test_ensemble)\n",
    "import FVMF\n",
    "importlib.reload(FVMF)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net4 = FVMF.BayesianNetwork(#w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa=torch.Tensor(1).uniform_(4.0,4.1),\n",
    "                                w_kappa=torch.Tensor(1).uniform_(6.0,6.1),\n",
    "                                Temper = 1,classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net4.parameters(), lr=0.14)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net4, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100, shape = data_shape)\n",
    "        #print('max:',net4.weight_mu[1].max())\n",
    "        #print('norm:',torch.norm(net4.weight_mu[1]))\n",
    "\n",
    "    #res = test_ensemble.test_ensemble(net4,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = data_shape)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")\n",
    "\n",
    "GC_intensity = 1\n",
    "\n",
    "#Kanskje er det en god idee å også arve kappaene, men halvere dem? Hva om vi også kjører på med litt normalizering av mu-ene her?\n",
    "#Hva med adaptiv kappa per lag? Det er jo bare en kappa per bias-lag.\n",
    "\n",
    "w_mu = []\n",
    "for i in range(len(net4.weight_mu)):\n",
    "    #print('\\n','torch.norm(net4.weight_mu[i]):',torch.norm(net4.weight_mu[i]))\n",
    "    w_mu.append(net4.weight_mu[i]/torch.norm(net4.weight_mu[i]))\n",
    "    #print('\\n','norm w_mu[i]',torch.norm(w_mu[i]))\n",
    "    \n",
    "b_mu = []\n",
    "for i in range(len(net4.bias_mu)):\n",
    "    #print('\\n','torch.norm(net4.bais_mu[i]):',torch.norm(net4.bias_mu[i]))\n",
    "    b_mu.append(net4.bias_mu[i]/torch.norm(net4.bias_mu[i]))\n",
    "    #print('\\n','norm b_mu[i]',torch.norm(b_mu[i]))\n",
    "    \n",
    "b_rho= []\n",
    "for i in range(len(net4.bias_rho)):\n",
    "    b_rho.append(net4.bias_rho[i]*GC_intensity)\n",
    "\n",
    "w_rho= []\n",
    "for i in range(len(net4.weight_rho)):\n",
    "    w_rho.append(net4.weight_rho[i]*GC_intensity)\n",
    "\n",
    "#print('b_rho:',b_rho, '\\n','w_rho:',b_mu)\n",
    "\n",
    "epochs = 10\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net4_GC = FVMF.BayesianNetwork(w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa= b_rho, #torch.Tensor(1).uniform_(1.0,3.1), \n",
    "                                w_kappa= w_rho, #torch.Tensor(1).uniform_(2.0,4.1), \n",
    "                                Temper = 1,classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net4_GC.parameters(), lr=0.07)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net4_GC, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100, shape = data_shape)\n",
    "        #print('max:',net4.weight_mu[1].max())\n",
    "        #print('norm:',torch.norm(net4.weight_mu[1]))\n",
    "\n",
    "    #res = test_ensemble.test_ensemble(net4_GC,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = data_shape)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")\n",
    "#print('This is the loss with the Gradient Capture method/Normalized Initialization Inheritance')\n",
    "\n",
    "#Ok, så kanskje drit i gradient-capture-method. Men! Husk hva du har vist her nå med kun normalisering av vektene, Du får trent nettet\n",
    "#Videre, og det fungerer faktisk. I tilfellet hvor du ikke gjør det ender du faktisk ikke bare opp med dårlig ytelse, men\n",
    "#hele nettet brekker!!!!!!!!!!!\n",
    "\n",
    "GC_intensity = 1\n",
    "\n",
    "#Kanskje er det en god idee å også arve kappaene, men halvere dem? Hva om vi også kjører på med litt normalizering av mu-ene her?\n",
    "#Hva med adaptiv kappa per lag? Det er jo bare en kappa per bias-lag. GC fungerer rett og slett ikke.\n",
    "\n",
    "w_mu = []\n",
    "for i in range(len(net4_GC.weight_mu)):\n",
    "    #print('\\n','torch.norm(net4.weight_mu[i]):',torch.norm(net4.weight_mu[i]))\n",
    "    w_mu.append(net4_GC.weight_mu[i]/torch.norm(net4_GC.weight_mu[i]))\n",
    "    #print('\\n','norm w_mu[i]',torch.norm(w_mu[i]))\n",
    "    \n",
    "b_mu = []\n",
    "for i in range(len(net4_GC.bias_mu)):\n",
    "    #print('\\n','torch.norm(net4.bais_mu[i]):',torch.norm(net4.bias_mu[i]))\n",
    "    b_mu.append(net4_GC.bias_mu[i]/torch.norm(net4_GC.bias_mu[i]))\n",
    "    #print('\\n','norm b_mu[i]',torch.norm(b_mu[i]))\n",
    "    \n",
    "b_rho= []\n",
    "for i in range(len(net4_GC.bias_rho)):\n",
    "    b_rho.append(net4_GC.bias_rho[i]*GC_intensity)\n",
    "\n",
    "w_rho= []\n",
    "for i in range(len(net4_GC.weight_rho)):\n",
    "    w_rho.append(net4_GC.weight_rho[i]*GC_intensity)\n",
    "\n",
    "#print('b_rho:',b_rho, '\\n','w_rho:',b_mu)\n",
    "\n",
    "epochs = 10\n",
    "for i in range(0, 1):\n",
    "    print(i)\n",
    "    torch.manual_seed(i)\n",
    "    net4_GC2 = FVMF.BayesianNetwork(w_mu = w_mu, b_mu = b_mu, \n",
    "                                #w_mu = None, b_mu = None,\n",
    "                                #w_mu = w_mu_nodewise, b_mu = b_mu,\n",
    "                                layershapes = layershapes,\n",
    "                                dtrain=dtrain, dtest=dtest,\n",
    "                                VD='vmf',\n",
    "                                b_kappa= b_rho, #torch.Tensor(1).uniform_(1.0,3.1), \n",
    "                                w_kappa= w_rho, #torch.Tensor(1).uniform_(2.0,4.1), \n",
    "                                Temper = 1,classification = 'classification')\n",
    "    \n",
    "    #for j,p in enumerate(net2.l1.parameters()):    \n",
    "    #    p.requires_grad_(False)\n",
    "    #    \n",
    "    #for j,p in enumerate(net2.l2.parameters()):\n",
    "    #    p.requires_grad_(False)\n",
    "    \n",
    "    optimizer = optim.Adam(net4_GC2.parameters(), lr=0.035)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        trtimes[epoch] = FVMF.train(net4_GC2, dtrain, SAMPLES, optimizer, epoch, i,BATCH_SIZE = 100, shape = data_shape)\n",
    "        #print('max:',net4.weight_mu[1].max())\n",
    "        #print('norm:',torch.norm(net4.weight_mu[1]))\n",
    "\n",
    "    res = test_ensemble.test_ensemble(net4_GC2,dtest,TEST_SAMPLES,TEST_BATCH_SIZE,BATCH_SIZE,CLASSES,DEVICE,shape = data_shape)\n",
    "\n",
    "    #np.savetxt(\"soundGmaccuracies_\" + str(i) + \".csv\", res, delimiter=\",\")\n",
    "print('This is the loss with the Gradient Capture method/Normalized Initialization Inheritance, applied twice')\n",
    "\n",
    "#Ok, så kanskje drit i gradient-capture-method. Men! Husk hva du har vist her nå med kun normalisering av vektene, Du får trent nettet\n",
    "#Videre, og det fungerer faktisk. I tilfellet hvor du ikke gjør det ender du faktisk ikke bare opp med dårlig ytelse, men\n",
    "#hele nettet brekker!!!!!!!!!!!\n",
    "\n",
    "RES = 1028 #Ca. Full HD resolution. If you struggle with memory adjust this parameter down. 64 for example already gives a decent view.\n",
    "enums = 10\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "Temps = torch.zeros((RES**2,3))\n",
    "i, j = 0, 0\n",
    "\n",
    "x = torch.linspace(-5,5,RES)\n",
    "\n",
    "Temps[:,:2] = torch.cartesian_prod(x, x)\n",
    "probs = torch.zeros((1,5)).to(DEVICE)\n",
    "\n",
    "for j in range(enums):\n",
    "    probs = probs + torch.exp(net4_GC2(Temps[:,0:2])) #This is done enums times, each one will be different due to stochastic.\n",
    "probs = probs/enums\n",
    "\n",
    "Temps[:,2] = -torch.sum(probs * torch.log(probs),dim = 1)\n",
    "print(torch.max(Temps[:,2]),torch.min(Temps[:,2]))\n",
    "\n",
    "plt.title('vMF Uncertainty Plot 42epocsLR0.1 3*10epocs, NII in between.')\n",
    "#xy = [0,0.2,0.4,0.6,0.8,1]\n",
    "#z = xy\n",
    "plot = plt.scatter(Temps[:,0].detach().numpy(), Temps[:,1].detach().numpy(),vmin = 0, vmax = 1.4, s=221000/(RES**2), c=Temps[:,2].detach().numpy(), cmap='RdYlBu', marker='s')\n",
    "plt.gcf().set_size_inches((14, 12))\n",
    "plt.colorbar(plot)\n",
    "plt.show()\n",
    "\n",
    "RES = 1028\n",
    "enums = 10\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "Temps2 = torch.zeros((RES**2,3))\n",
    "i, j = 0, 0\n",
    "\n",
    "x = torch.linspace(-5,5,RES)\n",
    "\n",
    "Temps2[:,:2] = torch.cartesian_prod(x, x)\n",
    "probs = torch.zeros((1,5)).to(DEVICE)\n",
    "\n",
    "for j in range(enums):\n",
    "    probs = probs + torch.exp(net3(Temps2[:,0:2])) #This is done enums times, each one will be different due to stochastic.\n",
    "probs = probs/enums\n",
    "\n",
    "Temps2[:,2] = -torch.sum(probs * torch.log(probs),dim = 1)\n",
    "print(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21acd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
